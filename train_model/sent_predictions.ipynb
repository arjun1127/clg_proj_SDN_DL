{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0d424d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved X_test.npy and y_test.npy with shape: (452, 10, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the CSVs\n",
    "# Load the data\n",
    "vehicle_df = pd.read_csv('/home/arjunrao/mini_proj_6/train_model/vehicle_data.csv')\n",
    "network_df = pd.read_csv('/home/arjunrao/mini_proj_6/train_model/network_data.csv')\n",
    "\n",
    "# Merge on `time_step` and `ap_id`\n",
    "vehicle_df['ap_id'] = vehicle_df['ap_id'].astype(str)\n",
    "network_df['ap_id'] = network_df['ap_id'].str.extract(r'(\\d+)').astype(str)  # clean `ap_1` to `1`\n",
    "merged_df = pd.merge(network_df, vehicle_df, on=['time_step', 'ap_id'])\n",
    "\n",
    "# Select relevant features\n",
    "features = ['avg_packet_rate', 'avg_latency', 'bandwidth_usage', 'speed', 'acceleration', 'active_nodes']\n",
    "merged_df = merged_df[[\"time_step\", \"ap_id\"] + features]\n",
    "# Normalize\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(merged_df[features])\n",
    "\n",
    "# Create sequences\n",
    "sequence_length = 10\n",
    "X, y = [], []\n",
    "for i in range(len(df_scaled) - sequence_length):\n",
    "    X.append(df_scaled[i:i + sequence_length])\n",
    "    y.append(df_scaled[i + sequence_length])  \n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42)\n",
    "\n",
    "# Save test data\n",
    "np.save(\"X_test.npy\", X_test)\n",
    "np.save(\"y_test.npy\", y_test)\n",
    "\n",
    "print(\"Saved X_test.npy and y_test.npy with shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39f32075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 10, 128)           69120     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10, 128)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118918 (464.52 KB)\n",
      "Trainable params: 118918 (464.52 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"network_congestion_lstm.h5\")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be367a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 15:46:37.534200: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-08 15:46:37.536958: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-08 15:46:37.594276: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-08 15:46:37.595474: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-08 15:46:38.537094: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ML prediction sender loop...\n",
      "[15:46:42] Sent batch prediction.\n",
      "[15:46:47] Sent batch prediction.\n",
      "[15:46:53] Sent batch prediction.\n",
      "[15:46:59] Sent batch prediction.\n",
      "[15:47:04] Sent batch prediction.\n",
      "[15:47:10] Sent batch prediction.\n",
      "[15:47:15] Sent batch prediction.\n",
      "[15:47:21] Sent batch prediction.\n",
      "[15:47:27] Sent batch prediction.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m sock\u001b[38;5;241m.\u001b[39msendto(json\u001b[38;5;241m.\u001b[39mdumps(payload)\u001b[38;5;241m.\u001b[39mencode(), (controller_ip, controller_port))\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Sent batch prediction.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import socket\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load LSTM model\n",
    "model = load_model(\"network_congestion_lstm.h5\")\n",
    "\n",
    "# Load test data\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "\n",
    "# Feature labels used (same order as during training)\n",
    "feature_labels = ['avg_packet_rate', 'avg_latency', 'bandwidth_usage', 'speed', 'acceleration', 'active_nodes']\n",
    "\n",
    "# Set up UDP\n",
    "controller_ip = \"127.0.0.1\"\n",
    "controller_port = 9999\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "\n",
    "print(\"Starting ML prediction sender loop...\")\n",
    "i = 0\n",
    "while True:\n",
    "    all_ap_predictions = []\n",
    "\n",
    "    for ap_id in range(1, 11):\n",
    "        if i >= X_test.shape[0]:\n",
    "            i = 0\n",
    "\n",
    "        x_input = X_test[i:i+1]\n",
    "        prediction = model.predict(x_input, verbose=0)[0]  # Shape (6,)\n",
    "\n",
    "        predicted_features = {\n",
    "            feature_labels[j]: round(float(prediction[j]), 4)\n",
    "            for j in range(len(feature_labels))\n",
    "        }\n",
    "\n",
    "        ap_data = {\n",
    "            \"ap_id\": ap_id,\n",
    "            \"predicted_features\": predicted_features\n",
    "        }\n",
    "\n",
    "        all_ap_predictions.append(ap_data)\n",
    "        i += 1\n",
    "\n",
    "    payload = {\n",
    "        \"type\": \"batch\",\n",
    "        \"data\": all_ap_predictions\n",
    "    }\n",
    "\n",
    "    sock.sendto(json.dumps(payload).encode(), (controller_ip, controller_port))\n",
    "    print(f\"[{time.strftime('%H:%M:%S')}] Sent batch prediction.\")\n",
    "\n",
    "    time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "473b7e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ML prediction sender loop...\n",
      "[13:18:37] Sent batch prediction.\n",
      "[13:18:42] Sent batch prediction.\n",
      "[13:18:48] Sent batch prediction.\n",
      "[13:18:53] Sent batch prediction.\n",
      "[13:18:58] Sent batch prediction.\n",
      "[13:19:04] Sent batch prediction.\n",
      "[13:19:09] Sent batch prediction.\n",
      "[13:19:14] Sent batch prediction.\n",
      "[13:19:20] Sent batch prediction.\n",
      "[13:19:25] Sent batch prediction.\n",
      "[13:19:30] Sent batch prediction.\n",
      "[13:19:36] Sent batch prediction.\n",
      "[13:19:41] Sent batch prediction.\n",
      "[13:19:46] Sent batch prediction.\n",
      "[13:19:52] Sent batch prediction.\n",
      "[13:19:57] Sent batch prediction.\n",
      "[13:20:02] Sent batch prediction.\n",
      "[13:20:08] Sent batch prediction.\n",
      "[13:20:13] Sent batch prediction.\n",
      "[13:20:18] Sent batch prediction.\n",
      "[13:20:24] Sent batch prediction.\n",
      "[13:20:29] Sent batch prediction.\n",
      "[13:20:34] Sent batch prediction.\n",
      "[13:20:40] Sent batch prediction.\n",
      "[13:20:45] Sent batch prediction.\n",
      "[13:20:50] Sent batch prediction.\n",
      "[13:20:56] Sent batch prediction.\n",
      "[13:21:01] Sent batch prediction.\n",
      "[13:21:07] Sent batch prediction.\n",
      "[13:21:12] Sent batch prediction.\n",
      "[13:21:17] Sent batch prediction.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     32\u001b[0m x_input \u001b[38;5;241m=\u001b[39m X_test[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 33\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Shape (6,)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m predicted_features \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     36\u001b[0m     feature_labels[j]: \u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mfloat\u001b[39m(prediction[j]), \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(feature_labels))\n\u001b[1;32m     38\u001b[0m }\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Compute simple congestion score (customize as needed)\u001b[39;00m\n",
      "File \u001b[0;32m~/mini_proj_6/lstm_venv/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/mini_proj_6/lstm_venv/lib/python3.8/site-packages/keras/src/engine/training.py:2550\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2548\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_predict_begin()\n\u001b[1;32m   2549\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2550\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, iterator \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():  \u001b[38;5;66;03m# Single epoch.\u001b[39;00m\n\u001b[1;32m   2551\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m   2552\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n",
      "File \u001b[0;32m~/mini_proj_6/lstm_venv/lib/python3.8/site-packages/keras/src/engine/data_adapter.py:1331\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[0;32m-> 1331\u001b[0m     data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epochs):\n\u001b[1;32m   1333\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n",
      "File \u001b[0;32m~/mini_proj_6/lstm_venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:506\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    509\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mini_proj_6/lstm_venv/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py:710\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    706\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 710\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/mini_proj_6/lstm_venv/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    746\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    747\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[1;32m    748\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[0;32m--> 749\u001b[0m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mini_proj_6/lstm_venv/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3420\u001b[0m, in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   3419\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3420\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3421\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3423\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import socket\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load LSTM model and test data\n",
    "model = load_model(\"network_congestion_lstm.h5\")\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "\n",
    "feature_labels = ['avg_packet_rate', 'avg_latency', 'bandwidth_usage', 'speed', 'acceleration', 'active_nodes']\n",
    "\n",
    "# MAC addresses for APs (1-10)\n",
    "ap_mac_map = {\n",
    "    i: f\"00:00:00:00:00:{i:02X}\" for i in range(1, 11)\n",
    "}\n",
    "\n",
    "# UDP setup\n",
    "controller_ip = \"127.0.0.1\"\n",
    "controller_port = 9999\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "\n",
    "print(\"Starting ML prediction sender loop...\")\n",
    "i = 0\n",
    "while True:\n",
    "    all_ap_predictions = []\n",
    "\n",
    "    for ap_id in range(1, 11):\n",
    "        if i >= X_test.shape[0]:\n",
    "            i = 0\n",
    "\n",
    "        x_input = X_test[i:i+1]\n",
    "        prediction = model.predict(x_input, verbose=0)[0]  # Shape (6,)\n",
    "\n",
    "        predicted_features = {\n",
    "            feature_labels[j]: round(float(prediction[j]), 4)\n",
    "            for j in range(len(feature_labels))\n",
    "        }\n",
    "\n",
    "        # Compute simple congestion score (customize as needed)\n",
    "        congestion_score = round(\n",
    "            0.4 * predicted_features['avg_packet_rate'] +\n",
    "            0.3 * predicted_features['avg_latency'] +\n",
    "            0.3 * predicted_features['bandwidth_usage'],\n",
    "            4\n",
    "        )\n",
    "\n",
    "        ap_data = {\n",
    "            \"ap_id\": ap_id,\n",
    "            \"mac\": ap_mac_map[ap_id],\n",
    "            \"congestion_score\": congestion_score,\n",
    "            **predicted_features\n",
    "        }\n",
    "\n",
    "        all_ap_predictions.append(ap_data)\n",
    "        i += 1\n",
    "\n",
    "    payload = {\n",
    "        \"type\": \"batch\",\n",
    "        \"data\": all_ap_predictions\n",
    "    }\n",
    "\n",
    "    sock.sendto(json.dumps(payload).encode(), (controller_ip, controller_port))\n",
    "    print(f\"[{time.strftime('%H:%M:%S')}] Sent batch prediction.\")\n",
    "\n",
    "    time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b533d4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"type\": \"batch\", \"data\": [{\"ap_id\": 1, \"mac\": \"00:00:00:00:00:01\", \"congestion_score\": 0.2959, \"avg_packet_rate\": 0.312, \"avg_latency\": 0.1938, \"bandwidth_usage\": 0.3764, \"speed\": 0.4976, \"acceleration\": 0.5483, \"active_nodes\": 0.6054}, {\"ap_id\": 2, \"mac\": \"00:00:00:00:00:02\", \"congestion_score\": 0.4786, \"avg_packet_rate\": 0.5296, \"avg_latency\": 0.3841, \"bandwidth_usage\": 0.505, \"speed\": 0.4943, \"acceleration\": 0.5578, \"active_nodes\": 0.8528}, {\"ap_id\": 3, \"mac\": \"00:00:00:00:00:03\", \"congestion_score\": 0.4803, \"avg_packet_rate\": 0.5042, \"avg_latency\": 0.4552, \"bandwidth_usage\": 0.4734, \"speed\": 0.5007, \"acceleration\": 0.5643, \"active_nodes\": 0.3438}, {\"ap_id\": 4, \"mac\": \"00:00:00:00:00:04\", \"congestion_score\": 0.5901, \"avg_packet_rate\": 0.7303, \"avg_latency\": 0.4, \"bandwidth_usage\": 0.5933, \"speed\": 0.5009, \"acceleration\": 0.5663, \"active_nodes\": 0.612}, {\"ap_id\": 5, \"mac\": \"00:00:00:00:00:05\", \"congestion_score\": 0.4738, \"avg_packet_rate\": 0.3654, \"avg_latency\": 0.4826, \"bandwidth_usage\": 0.6097, \"speed\": 0.4871, \"acceleration\": 0.5583, \"active_nodes\": -0.0155}, {\"ap_id\": 6, \"mac\": \"00:00:00:00:00:06\", \"congestion_score\": 0.5794, \"avg_packet_rate\": 0.6995, \"avg_latency\": 0.2781, \"bandwidth_usage\": 0.7206, \"speed\": 0.504, \"acceleration\": 0.5693, \"active_nodes\": 0.0634}, {\"ap_id\": 7, \"mac\": \"00:00:00:00:00:07\", \"congestion_score\": 0.5825, \"avg_packet_rate\": 0.6464, \"avg_latency\": 0.4444, \"bandwidth_usage\": 0.6355, \"speed\": 0.4998, \"acceleration\": 0.5644, \"active_nodes\": 0.2142}, {\"ap_id\": 8, \"mac\": \"00:00:00:00:00:08\", \"congestion_score\": 0.6089, \"avg_packet_rate\": 0.5729, \"avg_latency\": 0.8662, \"bandwidth_usage\": 0.3995, \"speed\": 0.5039, \"acceleration\": 0.5804, \"active_nodes\": 0.0868}, {\"ap_id\": 9, \"mac\": \"00:00:00:00:00:09\", \"congestion_score\": 0.5681, \"avg_packet_rate\": 0.5839, \"avg_latency\": 0.5374, \"bandwidth_usage\": 0.5777, \"speed\": 0.4947, \"acceleration\": 0.566, \"active_nodes\": 0.8468}, {\"ap_id\": 10, \"mac\": \"00:00:00:00:00:0A\", \"congestion_score\": 0.4947, \"avg_packet_rate\": 0.4864, \"avg_latency\": 0.5343, \"bandwidth_usage\": 0.4662, \"speed\": 0.4988, \"acceleration\": 0.5653, \"active_nodes\": 0.3431}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2141"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(json.dumps(payload))  # Log the payload to see what is being sent\n",
    "sock.sendto(json.dumps(payload).encode(), (controller_ip, controller_port))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32c9704b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg_packet_rate': 0.4864, 'avg_latency': 0.5343, 'bandwidth_usage': 0.4662, 'speed': 0.4988, 'acceleration': 0.5653, 'active_nodes': 0.3431}\n"
     ]
    }
   ],
   "source": [
    "print(predicted_features)  # Log to check the values\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
